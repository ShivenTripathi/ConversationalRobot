{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make corpus from nltk stuff(won't have to preprocess much)\n",
    "#train glove on that corpus\n",
    "#define functions you need\n",
    "#what do you need bruhh\n",
    "#make that nice co-occurrence matrix\n",
    "#figure out how optimisation works\n",
    "#figure out initiallisation\n",
    "#figure out training shizz\n",
    "#figure out how you exporting yo model and shizz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from keras.layers import Input, Embedding, Dot, Reshape, Add\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package brown to /home/shiven/nltk_data...\n[nltk_data]   Package brown is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "57340"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "data = brown.sents(categories=brown.categories())\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[]\n",
    "stopwords_ = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "punctuation = ['!','\"','#','$','%','&',\"'\",'(',')','*','+',',','-','.','/',':',';','<','=','>','?','@','[','\\\\',']','^','_','`','{','|','}','~','``',\"''\",'--']\n",
    "for sentence in data:\n",
    "    for word in stopwords_:\n",
    "        token=\" \"+word+\" \"\n",
    "        sentence=[item.replace(token,\" \") for item in sentence]\n",
    "    sentences.append(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    sentences[i]=[item.lower() for item in sentences[i]]\n",
    "    sentences[i]=[item*(len(item)>2) for item in sentences[i]]\n",
    "    for pun in punctuation:\n",
    "        sentences[i]=[item.replace(pun,\"\") for item in sentences[i]]\n",
    "        sentences[i]=[item for item in sentences[i] if item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['daniel', 'personally', 'led', 'the', 'fight', 'for', 'the', 'measure', 'which', 'had', 'watered', 'down', 'considerably', 'since', 'its', 'rejection', 'two', 'previous', 'legislatures', 'public', 'hearing', 'before', 'the', 'house', 'committee', 'revenue', 'and', 'taxation']\n"
    }
   ],
   "source": [
    "print(sentences[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=10000\n",
    "vector_dim=100\n",
    "maxlen=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "sequences_padded = pad_sequences(sequences, padding='post', maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['ruths', 'day', 'and', 'until', 'this', 'year', 'the', 'schedule', 'was', '154', 'games']\n[9126, 107, 3, 160, 9, 116, 2, 2953, 5, 1, 1817]\n[9126  107    3  160    9  116    2 2953    5    1 1817    0    0    0\n    0    0    0    0    0    0]\n11\n11\n20\n"
    }
   ],
   "source": [
    "print(sentences[4000])\n",
    "print(sequences[4000])\n",
    "print(sequences_padded[4000])\n",
    "print(len(sentences[4000]))\n",
    "print(len(sequences[4000]))\n",
    "print(len(sequences_padded[4000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.6 64-bit ('try_run': conda)",
   "language": "python",
   "name": "python35664bittryruncondab95fb79d8757413d8f8d35d52e41ba00"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}