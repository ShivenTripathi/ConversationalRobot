{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "IMDB Dataset on custom GloVe Model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%202%20-%20Exercise%20-%20Answer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "BZSlp3DAjdYf",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gnwiOnGyW5JK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bc9d0c5-ed4c-45f5-e8d3-170862b0028c"
      },
      "source": [
        "import numpy as np\n",
        "from keras.layers import Input, Embedding, Dot, Reshape, Add\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "import nltk\n",
        "from nltk.corpus import brown"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EYo6A4v5ZABQ",
        "outputId": "83b87e73-7f45-4823-e9f3-2a00419b0642",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('brown')\n",
        "data = brown.sents(categories=brown.categories())\n",
        "len(data)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57340"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iU1qq3_SZBx_",
        "colab": {}
      },
      "source": [
        "sentences=[]\n",
        "stopwords_ = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "punctuation = ['!','\"','#','$','%','&',\"'\",'(',')','*','+',',','-','.','/',':',';','<','=','>','?','@','[','\\\\',']','^','_','`','{','|','}','~','``',\"''\",'--']\n",
        "for sentence in data:\n",
        "    for word in stopwords_:\n",
        "        token=\" \"+word+\" \"\n",
        "        sentence=[item.replace(token,\" \") for item in sentence]\n",
        "    sentences.append(sentence)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eutB2xMiZD0e",
        "outputId": "39a56265-ccc5-421d-d76a-b59b0fe9ff34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "for i in range(len(sentences)):\n",
        "    sentences[i]=[item.lower() for item in sentences[i]]\n",
        "    sentences[i]=[item*(len(item)>2) for item in sentences[i]]\n",
        "    for pun in punctuation:\n",
        "        sentences[i]=[item.replace(pun,\"\") for item in sentences[i]]\n",
        "        sentences[i]=[item for item in sentences[i] if item]\n",
        "print(sentences[100])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['daniel', 'personally', 'led', 'the', 'fight', 'for', 'the', 'measure', 'which', 'had', 'watered', 'down', 'considerably', 'since', 'its', 'rejection', 'two', 'previous', 'legislatures', 'public', 'hearing', 'before', 'the', 'house', 'committee', 'revenue', 'and', 'taxation']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XfdaWh06ZGe3",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ULzA8xhwZI22",
        "colab": {}
      },
      "source": [
        "vocab_size=10000\n",
        "vector_dim=100\n",
        "maxlen=20\n",
        "windowSize=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c8PeFWzPZLW_",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XkWiQ_FKZNp2",
        "colab": {}
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "sequences_padded = pad_sequences(sequences, padding='post', maxlen=maxlen)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jFwm_Gs7tDU",
        "colab_type": "code",
        "outputId": "1235a1f7-a402-448d-e0fb-7f8b66a96523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(sentences[4000])\n",
        "print(sequences[4000])\n",
        "print(sequences_padded[4000])\n",
        "print(len(sentences[4000]))\n",
        "print(len(sequences[4000]))\n",
        "print(len(sequences_padded[4000]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ruths', 'day', 'and', 'until', 'this', 'year', 'the', 'schedule', 'was', '154', 'games']\n",
            "[9177, 108, 3, 161, 9, 117, 2, 2968, 5, 1, 1826]\n",
            "[9177  108    3  161    9  117    2 2968    5    1 1826    0    0    0\n",
            "    0    0    0    0    0    0]\n",
            "11\n",
            "11\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNjy7AzL7tOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "co_matrix = defaultdict(lambda: defaultdict(int))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjMRuQEY7tYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sentence in sequences_padded:\n",
        "    sentence_size=len(sentence)\n",
        "    for i in range(sentence_size):\n",
        "        for distance in range(1,windowSize+1):\n",
        "            if i+distance<sentence_size:\n",
        "                if sentence[i]>sentence[i+distance]:\n",
        "                    first=sentence[i+distance]\n",
        "                    second=sentence[i]\n",
        "                else:\n",
        "                    second=sentence[i+distance]\n",
        "                    first=sentence[i]\n",
        "                co_matrix[first][second]+=1.0/distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdeWp3Fq7qzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first,second,freqs=[],[],[]\n",
        "for first_id in co_matrix.keys():\n",
        "    for second_id in co_matrix[first_id].keys():\n",
        "        freq=co_matrix[first_id][second_id]\n",
        "        first.append(first_id)\n",
        "        second.append(second_id)\n",
        "        freqs.append(freq)\n",
        "        first.append(second_id)\n",
        "        second.append(first_id)\n",
        "        freqs.append(freq)\n",
        "first=np.array(first)\n",
        "second=np.array(second)\n",
        "freqs=np.array(freqs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKn2QPAq77Oq",
        "colab_type": "code",
        "outputId": "7b809556-f996-4a00-8650-d0e129bfcaf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(np.shape(first))\n",
        "print(np.shape(second))\n",
        "print(np.shape(freqs))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1306226,)\n",
            "(1306226,)\n",
            "(1306226,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUOPOBZ477X8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#time for modelling yay!\n",
        "#shamelessly copied loss haha\n",
        "X_MAX = 100\n",
        "a = 3.0 / 4.0\n",
        "def customLoss(y_true,y_pred):\n",
        "    return K.sum(K.pow(K.clip(y_true / X_MAX, 0.0, 1.0), a) * K.square(y_pred - K.log(y_true)), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqk7nuEz77lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_target = Input((1,))\n",
        "input_context = Input((1,))\n",
        "\n",
        "central_embedding = Embedding(vocab_size, vector_dim, input_length=1,name='cen_e')\n",
        "central_bias = Embedding(vocab_size, 1, input_length=1)\n",
        "\n",
        "context_embedding = Embedding(vocab_size, vector_dim, input_length=1,name='con_e')\n",
        "context_bias = Embedding(vocab_size, 1, input_length=1)\n",
        "\n",
        "vector_target = central_embedding(input_target)\n",
        "vector_context = context_embedding(input_context)\n",
        "\n",
        "bias_target = central_bias(input_target)\n",
        "bias_context = context_bias(input_context)\n",
        "\n",
        "dot_product = Dot(axes=-1)([vector_target, vector_context])\n",
        "dot_product = Reshape((1, ))(dot_product)\n",
        "bias_target = Reshape((1,))(bias_target)\n",
        "bias_context = Reshape((1,))(bias_context)\n",
        "\n",
        "prediction = Add()([dot_product, bias_target, bias_context])\n",
        "\n",
        "model = Model(inputs=[input_target, input_context], outputs=prediction)\n",
        "model.compile(loss=customLoss, optimizer=Adam())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65CM_DBswCYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=50\n",
        "batch_size=1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jBpDIdqA3X2",
        "colab_type": "code",
        "outputId": "8b8206a1-91e7-4d8b-fd32-e7a05c6eb475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit([first, second], freqs, epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0193\n",
            "Epoch 2/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0177\n",
            "Epoch 3/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0157\n",
            "Epoch 4/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0134\n",
            "Epoch 5/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0114\n",
            "Epoch 6/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0098\n",
            "Epoch 7/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0085\n",
            "Epoch 8/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0074\n",
            "Epoch 9/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0065\n",
            "Epoch 10/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0057\n",
            "Epoch 11/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0051\n",
            "Epoch 12/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0046\n",
            "Epoch 13/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0042\n",
            "Epoch 14/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0038\n",
            "Epoch 15/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0035\n",
            "Epoch 16/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0033\n",
            "Epoch 17/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0031\n",
            "Epoch 18/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0029\n",
            "Epoch 19/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0028\n",
            "Epoch 20/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0026\n",
            "Epoch 21/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0025\n",
            "Epoch 22/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0024\n",
            "Epoch 23/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0024\n",
            "Epoch 24/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0023\n",
            "Epoch 25/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0022\n",
            "Epoch 26/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0022\n",
            "Epoch 27/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0021\n",
            "Epoch 28/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0020\n",
            "Epoch 29/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0020\n",
            "Epoch 30/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0020\n",
            "Epoch 31/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0019\n",
            "Epoch 32/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0019\n",
            "Epoch 33/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0019\n",
            "Epoch 34/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0018\n",
            "Epoch 35/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0018\n",
            "Epoch 36/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0018\n",
            "Epoch 37/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0018\n",
            "Epoch 38/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0017\n",
            "Epoch 39/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0017\n",
            "Epoch 40/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0017\n",
            "Epoch 41/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0017\n",
            "Epoch 42/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0016\n",
            "Epoch 43/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0016\n",
            "Epoch 44/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0016\n",
            "Epoch 45/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0016\n",
            "Epoch 46/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0016\n",
            "Epoch 47/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0016\n",
            "Epoch 48/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0016\n",
            "Epoch 49/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0015\n",
            "Epoch 50/50\n",
            "1306226/1306226 [==============================] - 5s 4us/step - loss: 0.0015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f78183bdfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMcA5Cx2vqXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dfeb5173-0cde-446b-b5d6-a71a171b12ea"
      },
      "source": [
        "cen_e=central_embedding.get_weights()\n",
        "con_e=context_embedding.get_weights()\n",
        "print(np.shape(cen_e))\n",
        "print(np.shape(con_e))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 10000, 100)\n",
            "(1, 10000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfs35sMMvsU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " emb_matrix = np.zeros((vocab_size,vector_dim))\n",
        " word_2_vec={}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diRe7PoNvvB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(vocab_size):\n",
        "    emb_matrix[i]=(con_e[0][i]+cen_e[0][i])/2\n",
        "    word_2_vec[str(tokenizer.index_word[1+i])]=emb_matrix[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBSKucEv8D0z",
        "colab_type": "code",
        "outputId": "0d18fc59-cda1-4bfb-9842-d460af10eebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import csv\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/bbc-text.csv \\\n",
        "    -O /tmp/bbc-text.csv\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_portion = .8"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-22 19:09:42--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/bbc-text.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.79.128, 2a00:1450:4013:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.79.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5057493 (4.8M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/bbc-text.csv’\n",
            "\n",
            "\r/tmp/bbc-text.csv     0%[                    ]       0  --.-KB/s               \r/tmp/bbc-text.csv   100%[===================>]   4.82M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-05-22 19:09:42 (246 MB/s) - ‘/tmp/bbc-text.csv’ saved [5057493/5057493]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk7ZXjje87AZ",
        "colab_type": "code",
        "outputId": "85731b9f-d126-41e7-b815-53dc50d8ac6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentences = []\n",
        "labels = []\n",
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "print(len(stopwords))\n",
        "# Expected Output\n",
        "# 153"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ-gte5A87Lm",
        "colab_type": "code",
        "outputId": "a0d5d9f9-9a41-4720-ee43-5af868cf232c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "with open(\"/tmp/bbc-text.csv\", 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        labels.append(row[0])\n",
        "        sentence = row[1]\n",
        "        for word in stopwords:\n",
        "            token = \" \" + word + \" \"\n",
        "            sentence = sentence.replace(token, \" \")\n",
        "        sentences.append(sentence)\n",
        "\n",
        "print(len(labels))\n",
        "print(len(sentences))\n",
        "print(sentences[0])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2225\n",
            "2225\n",
            "tv future hands viewers home theatre systems  plasma high-definition tvs  digital video recorders moving living room  way people watch tv will radically different five years  time.  according expert panel gathered annual consumer electronics show las vegas discuss new technologies will impact one favourite pastimes. us leading trend  programmes content will delivered viewers via home networks  cable  satellite  telecoms companies  broadband service providers front rooms portable devices.  one talked-about technologies ces digital personal video recorders (dvr pvr). set-top boxes  like us s tivo uk s sky+ system  allow people record  store  play  pause forward wind tv programmes want.  essentially  technology allows much personalised tv. also built-in high-definition tv sets  big business japan us  slower take off europe lack high-definition programming. not can people forward wind adverts  can also forget abiding network channel schedules  putting together a-la-carte entertainment. us networks cable satellite companies worried means terms advertising revenues well  brand identity  viewer loyalty channels. although us leads technology moment  also concern raised europe  particularly growing uptake services like sky+.  happens today  will see nine months years  time uk   adam hume  bbc broadcast s futurologist told bbc news website. likes bbc  no issues lost advertising revenue yet. pressing issue moment commercial uk broadcasters  brand loyalty important everyone.  will talking content brands rather network brands   said tim hanlon  brand communications firm starcom mediavest.  reality broadband connections  anybody can producer content.  added:  challenge now hard promote programme much choice.   means  said stacey jolna  senior vice president tv guide tv group  way people find content want watch simplified tv viewers. means networks  us terms  channels take leaf google s book search engine future  instead scheduler help people find want watch. kind channel model might work younger ipod generation used taking control gadgets play them. might not suit everyone  panel recognised. older generations comfortable familiar schedules channel brands know getting. perhaps not want much choice put hands  mr hanlon suggested.  end  kids just diapers pushing buttons already - everything possible available   said mr hanlon.  ultimately  consumer will tell market want.   50 000 new gadgets technologies showcased ces  many enhancing tv-watching experience. high-definition tv sets everywhere many new models lcd (liquid crystal display) tvs launched dvr capability built  instead external boxes. one example launched show humax s 26-inch lcd tv 80-hour tivo dvr dvd recorder. one us s biggest satellite tv companies  directtv  even launched branded dvr show 100-hours recording capability  instant replay  search function. set can pause rewind tv 90 hours. microsoft chief bill gates announced pre-show keynote speech partnership tivo  called tivotogo  means people can play recorded programmes windows pcs mobile devices. reflect increasing trend freeing multimedia people can watch want  want.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuOybhQ887S0",
        "colab_type": "code",
        "outputId": "37335db5-5040-4734-f6ff-e72c22ad2437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "train_size = int(len(sentences) * training_portion)\n",
        "\n",
        "train_sentences = sentences[:train_size]\n",
        "train_labels = labels[:train_size]\n",
        "\n",
        "validation_sentences = sentences[train_size:]\n",
        "validation_labels = labels[train_size:]\n",
        "\n",
        "print(train_size)\n",
        "print(len(train_sentences))\n",
        "print(len(train_labels))\n",
        "print(len(validation_sentences))\n",
        "print(len(validation_labels))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1780\n",
            "1780\n",
            "1780\n",
            "445\n",
            "445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4oews9a87ab",
        "colab_type": "code",
        "outputId": "84ab8d94-449e-48a2-e5f4-4e9fa25e6077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
        "\n",
        "print(len(train_sequences[0]))\n",
        "print(len(train_padded[0]))\n",
        "\n",
        "print(len(train_sequences[1]))\n",
        "print(len(train_padded[1]))\n",
        "\n",
        "print(len(train_sequences[10]))\n",
        "print(len(train_padded[10]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "449\n",
            "120\n",
            "200\n",
            "120\n",
            "192\n",
            "120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjt55kv99GAo",
        "colab_type": "code",
        "outputId": "e31f4c7c-93c5-4886-f037-ef450c93461f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "validation_sequences = tokenizer.texts_to_sequences(validation_sentences)\n",
        "validation_padded = pad_sequences(validation_sequences, padding=padding_type, maxlen=max_length)\n",
        "\n",
        "print(len(validation_sequences))\n",
        "print(validation_padded.shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "445\n",
            "(445, 120)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSzppgTF9GOo",
        "colab_type": "code",
        "outputId": "7227880e-4acc-4e83-d1dd-3d7167428ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "label_tokenizer = Tokenizer()\n",
        "label_tokenizer.fit_on_texts(labels)\n",
        "\n",
        "training_label_seq = np.array(label_tokenizer.texts_to_sequences(train_labels))\n",
        "validation_label_seq = np.array(label_tokenizer.texts_to_sequences(validation_labels))\n",
        "\n",
        "print(training_label_seq[0])\n",
        "print(training_label_seq[1])\n",
        "print(training_label_seq[2])\n",
        "print(training_label_seq.shape)\n",
        "\n",
        "print(validation_label_seq[0])\n",
        "print(validation_label_seq[1])\n",
        "print(validation_label_seq[2])\n",
        "print(validation_label_seq.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4]\n",
            "[2]\n",
            "[1]\n",
            "(1780, 1)\n",
            "[5]\n",
            "[4]\n",
            "[3]\n",
            "(445, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HZ5um4MWZP-W",
        "outputId": "80330884-09f1-46a2-8305-0ffdc69f6f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Embedding\n",
        "import keras\n",
        "model_i=Sequential()\n",
        "model_i.add(Embedding(vocab_size, vector_dim, weights=[emb_matrix], input_length=120, trainable=False))\n",
        "model_i.add(keras.layers.GlobalAveragePooling1D())\n",
        "model_i.add(keras.layers.Dense(64, activation='relu'))\n",
        "model_i.add(keras.layers.Dense(6, activation='softmax'))\n",
        "model_i.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model_i.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 120, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_3 ( (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                6464      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 1,006,854\n",
            "Trainable params: 6,854\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XsfdxySKZSXu",
        "outputId": "015b8a99-54eb-4d4f-db0f-babaa35cee32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs = 60\n",
        "history = model_i.fit(train_padded, training_label_seq, epochs=num_epochs, validation_data=(validation_padded, validation_label_seq), verbose=2)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1780 samples, validate on 445 samples\n",
            "Epoch 1/60\n",
            " - 0s - loss: 0.9953 - accuracy: 0.6404 - val_loss: 1.1117 - val_accuracy: 0.5865\n",
            "Epoch 2/60\n",
            " - 0s - loss: 0.9859 - accuracy: 0.6444 - val_loss: 1.0891 - val_accuracy: 0.5955\n",
            "Epoch 3/60\n",
            " - 0s - loss: 0.9784 - accuracy: 0.6500 - val_loss: 1.1052 - val_accuracy: 0.5753\n",
            "Epoch 4/60\n",
            " - 0s - loss: 0.9704 - accuracy: 0.6528 - val_loss: 1.0879 - val_accuracy: 0.5888\n",
            "Epoch 5/60\n",
            " - 0s - loss: 0.9648 - accuracy: 0.6517 - val_loss: 1.0907 - val_accuracy: 0.5955\n",
            "Epoch 6/60\n",
            " - 0s - loss: 0.9570 - accuracy: 0.6590 - val_loss: 1.0761 - val_accuracy: 0.6045\n",
            "Epoch 7/60\n",
            " - 0s - loss: 0.9532 - accuracy: 0.6579 - val_loss: 1.0664 - val_accuracy: 0.6180\n",
            "Epoch 8/60\n",
            " - 0s - loss: 0.9418 - accuracy: 0.6680 - val_loss: 1.0502 - val_accuracy: 0.6157\n",
            "Epoch 9/60\n",
            " - 0s - loss: 0.9412 - accuracy: 0.6596 - val_loss: 1.0527 - val_accuracy: 0.6135\n",
            "Epoch 10/60\n",
            " - 0s - loss: 0.9365 - accuracy: 0.6629 - val_loss: 1.0554 - val_accuracy: 0.6067\n",
            "Epoch 11/60\n",
            " - 0s - loss: 0.9276 - accuracy: 0.6556 - val_loss: 1.0600 - val_accuracy: 0.6202\n",
            "Epoch 12/60\n",
            " - 0s - loss: 0.9231 - accuracy: 0.6669 - val_loss: 1.0786 - val_accuracy: 0.5933\n",
            "Epoch 13/60\n",
            " - 0s - loss: 0.9204 - accuracy: 0.6680 - val_loss: 1.0468 - val_accuracy: 0.6045\n",
            "Epoch 14/60\n",
            " - 0s - loss: 0.9137 - accuracy: 0.6725 - val_loss: 1.0628 - val_accuracy: 0.5955\n",
            "Epoch 15/60\n",
            " - 0s - loss: 0.9085 - accuracy: 0.6708 - val_loss: 1.0343 - val_accuracy: 0.6292\n",
            "Epoch 16/60\n",
            " - 0s - loss: 0.9111 - accuracy: 0.6652 - val_loss: 1.0288 - val_accuracy: 0.6292\n",
            "Epoch 17/60\n",
            " - 0s - loss: 0.8994 - accuracy: 0.6747 - val_loss: 1.0314 - val_accuracy: 0.6225\n",
            "Epoch 18/60\n",
            " - 0s - loss: 0.8989 - accuracy: 0.6725 - val_loss: 1.0140 - val_accuracy: 0.6382\n",
            "Epoch 19/60\n",
            " - 0s - loss: 0.8954 - accuracy: 0.6730 - val_loss: 1.0411 - val_accuracy: 0.6270\n",
            "Epoch 20/60\n",
            " - 0s - loss: 0.8891 - accuracy: 0.6826 - val_loss: 1.0324 - val_accuracy: 0.6382\n",
            "Epoch 21/60\n",
            " - 0s - loss: 0.8902 - accuracy: 0.6742 - val_loss: 1.0206 - val_accuracy: 0.6135\n",
            "Epoch 22/60\n",
            " - 0s - loss: 0.8844 - accuracy: 0.6803 - val_loss: 1.0158 - val_accuracy: 0.6360\n",
            "Epoch 23/60\n",
            " - 0s - loss: 0.8788 - accuracy: 0.6798 - val_loss: 1.0154 - val_accuracy: 0.6360\n",
            "Epoch 24/60\n",
            " - 0s - loss: 0.8785 - accuracy: 0.6848 - val_loss: 1.0178 - val_accuracy: 0.6292\n",
            "Epoch 25/60\n",
            " - 0s - loss: 0.8741 - accuracy: 0.6809 - val_loss: 1.0362 - val_accuracy: 0.6135\n",
            "Epoch 26/60\n",
            " - 0s - loss: 0.8690 - accuracy: 0.6792 - val_loss: 1.0174 - val_accuracy: 0.6292\n",
            "Epoch 27/60\n",
            " - 0s - loss: 0.8679 - accuracy: 0.6860 - val_loss: 1.0176 - val_accuracy: 0.6157\n",
            "Epoch 28/60\n",
            " - 0s - loss: 0.8640 - accuracy: 0.6848 - val_loss: 1.0163 - val_accuracy: 0.6360\n",
            "Epoch 29/60\n",
            " - 0s - loss: 0.8616 - accuracy: 0.6843 - val_loss: 0.9942 - val_accuracy: 0.6360\n",
            "Epoch 30/60\n",
            " - 0s - loss: 0.8623 - accuracy: 0.6871 - val_loss: 1.0050 - val_accuracy: 0.6292\n",
            "Epoch 31/60\n",
            " - 0s - loss: 0.8596 - accuracy: 0.6871 - val_loss: 1.0158 - val_accuracy: 0.6225\n",
            "Epoch 32/60\n",
            " - 0s - loss: 0.8543 - accuracy: 0.6904 - val_loss: 1.0227 - val_accuracy: 0.6067\n",
            "Epoch 33/60\n",
            " - 0s - loss: 0.8507 - accuracy: 0.6921 - val_loss: 0.9939 - val_accuracy: 0.6517\n",
            "Epoch 34/60\n",
            " - 0s - loss: 0.8528 - accuracy: 0.6904 - val_loss: 1.0207 - val_accuracy: 0.6360\n",
            "Epoch 35/60\n",
            " - 0s - loss: 0.8480 - accuracy: 0.6848 - val_loss: 0.9858 - val_accuracy: 0.6517\n",
            "Epoch 36/60\n",
            " - 0s - loss: 0.8431 - accuracy: 0.6882 - val_loss: 0.9960 - val_accuracy: 0.6315\n",
            "Epoch 37/60\n",
            " - 0s - loss: 0.8426 - accuracy: 0.6882 - val_loss: 0.9890 - val_accuracy: 0.6427\n",
            "Epoch 38/60\n",
            " - 0s - loss: 0.8397 - accuracy: 0.7006 - val_loss: 0.9818 - val_accuracy: 0.6315\n",
            "Epoch 39/60\n",
            " - 0s - loss: 0.8402 - accuracy: 0.6916 - val_loss: 1.0230 - val_accuracy: 0.6157\n",
            "Epoch 40/60\n",
            " - 0s - loss: 0.8360 - accuracy: 0.6893 - val_loss: 0.9921 - val_accuracy: 0.6472\n",
            "Epoch 41/60\n",
            " - 0s - loss: 0.8296 - accuracy: 0.7022 - val_loss: 0.9733 - val_accuracy: 0.6292\n",
            "Epoch 42/60\n",
            " - 0s - loss: 0.8484 - accuracy: 0.6837 - val_loss: 0.9806 - val_accuracy: 0.6562\n",
            "Epoch 43/60\n",
            " - 0s - loss: 0.8318 - accuracy: 0.6944 - val_loss: 0.9926 - val_accuracy: 0.6449\n",
            "Epoch 44/60\n",
            " - 0s - loss: 0.8292 - accuracy: 0.7022 - val_loss: 0.9774 - val_accuracy: 0.6517\n",
            "Epoch 45/60\n",
            " - 0s - loss: 0.8266 - accuracy: 0.6966 - val_loss: 0.9747 - val_accuracy: 0.6404\n",
            "Epoch 46/60\n",
            " - 0s - loss: 0.8248 - accuracy: 0.6972 - val_loss: 0.9743 - val_accuracy: 0.6404\n",
            "Epoch 47/60\n",
            " - 0s - loss: 0.8277 - accuracy: 0.7017 - val_loss: 1.0036 - val_accuracy: 0.6337\n",
            "Epoch 48/60\n",
            " - 0s - loss: 0.8237 - accuracy: 0.6983 - val_loss: 0.9816 - val_accuracy: 0.6562\n",
            "Epoch 49/60\n",
            " - 0s - loss: 0.8180 - accuracy: 0.7000 - val_loss: 0.9746 - val_accuracy: 0.6674\n",
            "Epoch 50/60\n",
            " - 0s - loss: 0.8158 - accuracy: 0.7017 - val_loss: 0.9929 - val_accuracy: 0.6382\n",
            "Epoch 51/60\n",
            " - 0s - loss: 0.8146 - accuracy: 0.7039 - val_loss: 0.9610 - val_accuracy: 0.6494\n",
            "Epoch 52/60\n",
            " - 0s - loss: 0.8129 - accuracy: 0.7045 - val_loss: 0.9624 - val_accuracy: 0.6517\n",
            "Epoch 53/60\n",
            " - 0s - loss: 0.8122 - accuracy: 0.7118 - val_loss: 0.9687 - val_accuracy: 0.6607\n",
            "Epoch 54/60\n",
            " - 0s - loss: 0.8098 - accuracy: 0.7011 - val_loss: 0.9743 - val_accuracy: 0.6562\n",
            "Epoch 55/60\n",
            " - 0s - loss: 0.8066 - accuracy: 0.7067 - val_loss: 0.9793 - val_accuracy: 0.6382\n",
            "Epoch 56/60\n",
            " - 0s - loss: 0.8072 - accuracy: 0.7056 - val_loss: 0.9850 - val_accuracy: 0.6427\n",
            "Epoch 57/60\n",
            " - 0s - loss: 0.8031 - accuracy: 0.7051 - val_loss: 0.9613 - val_accuracy: 0.6539\n",
            "Epoch 58/60\n",
            " - 0s - loss: 0.8035 - accuracy: 0.7107 - val_loss: 0.9731 - val_accuracy: 0.6607\n",
            "Epoch 59/60\n",
            " - 0s - loss: 0.8038 - accuracy: 0.7062 - val_loss: 0.9776 - val_accuracy: 0.6674\n",
            "Epoch 60/60\n",
            " - 0s - loss: 0.8008 - accuracy: 0.7079 - val_loss: 0.9806 - val_accuracy: 0.6472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeJwiphY25Qp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b20faafd-a9d2-4292-ae5f-ee5ecaad0dcd"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_sentence(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "e = model_i.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91qSypxH5GbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qfv_psh5IGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}